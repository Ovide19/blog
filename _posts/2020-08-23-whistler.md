---
layout: posts
title: Listening to whistlers using SciPy, pyaudio and PyQt5
published: true
header:
  overlay_image: /assets/images/palmer_overlay.jpg
  overlay_filter: 0.2
tags: [SciPy, pyaudio, PyQt5]
date: 2020-08-23
---

**Work in progress**

Have you ever wondered how Earth's natural magnetic field *sounded* like?
Let's check it out!

In this post, we will write a script allowing to plot the spectrogram of Very Low Frequency (VLF) magnetic data, while simultaneously listening to them.
You've read it right: VLF data have their frequency comprised between 300Hz and 300kHz, the frequency range perceived by the human ear.

Let's first grab a sample data file from [the Worldwide Archive of Low-Frequency Data and Observation's website](http://waldo.world/), also known as WALDO. In this example, I will use data collected at the Palmer Antarctica Station. Data are stored as 1 minute chunks: I randomly picked the file acquired on January 1, 2012, at 02:10AM, which unzips as a .mat file named PA120101021000_021.mat. 


### 1. Importing libraries

There are quite a few tools needed here, starting with SciPy's `loadmat` which will allow to load the aforementioned .mat file into Python:

```python
import sys
import numpy as np
import wave
from scipy.io.wavfile import write
from scipy.io import loadmat
```

For the display, we will use an Anti-Grain Geometry rendering in a Qt5 canvas (`matplotlib.use('Qt5Agg')`):

```python
import matplotlib
import matplotlib.pyplot as plt
matplotlib.use('Qt5Agg')
from PyQt5 import QtCore, QtWidgets
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
```

We also need `pyaudio` to play the soundtrack associated with the data array:

```python
import pyaudio
```

Last but not least, we want to display the spectrogram and play the audio file *at the same time*, which requires the use of the multiprocessing module:

```python
import multiprocessing
```


### 2. Playing the audio file

```python
def audiostream(queue, filename):

     #    open stream

    wf = wave.open(filename, 'rb')
    CHUNK=1024
    p = pyaudio.PyAudio()
 
    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),
                     channels=wf.getnchannels(),
                     rate=wf.getframerate(),
                     output=True)
         

    data = wf.readframes(CHUNK)
     
    # play stream
    while len(data) > 0:
         stream.write(data)
         data = wf.readframes(CHUNK)
     
     # stop stream
    stream.stop_stream()
    stream.close()
     
     # close PyAudio
    p.terminate()
```



#### 3. Displaying the data


```python
class MplCanvas(FigureCanvas):

    def __init__(self, parent=None, width=5, height=2.5, dpi=100):
        fig = Figure(figsize=(width, height), dpi=dpi)
        self.axes = fig.add_subplot(111)
        super(MplCanvas, self).__init__(fig)
```

```python
class MainWindow(QtWidgets.QMainWindow):

    def __init__(self, *args, **kwargs):
        super(MainWindow, self).__init__(*args, **kwargs)

        self.canvas = MplCanvas(self, width=6, height=3.5, dpi=100)
        self.setCentralWidget(self.canvas)
        self.timer_id = 0
        self.ydata = data        
        self.update_plot()
        self.show()
     
        self.timer = QtCore.QTimer()
        self.timer.setInterval(timer_interval_in_ms)
        self.timer.timeout.connect(self.update_plot)
        self.timer.start()

    def update_plot(self):
        if not self.timer_id:
            spectrum, freqs, t, im = self.canvas.axes.specgram(data, Fs=fs, detrend="mean", cmap='hsv')
            self.canvas.axes.set_ylim(0,8000)
            self.canvas.axes.set_xlim(0,duration)
            self.canvas.axes.set_ylabel('Frequency (Hz)')
            self.canvas.axes.set_xlabel('Time (s)')
            self.vline = self.canvas.axes.axvline(x=self.timer_id)
        else:
            self.vline.set_xdata(self.timer_id)
            self.canvas.axes.set_title("Time: "+str("{:.2f}".format(self.timer_id))+"s")
        self.canvas.draw()
        self.timer_id += timer_interval_in_ms / 1000
```

```python
def run_display():
     app = QtWidgets.QApplication(sys.argv)
     w = MainWindow()
     app.exec_()
```

#### 4. Running the main program

```python
if __name__ == '__main__':     
     matfilename = 'PA120101021000_021.mat'
     filename = matfilename.split('.')[0]+'.wav' #Name of the wav file
     fs = 100000 #Actual sampling rate of the geomagnetic data
     x = loadmat(matfilename) 
     data=x['data'][:,0][:] #Array
     write(filename, fs, data)
     timer_interval_in_ms = 470
     
     wf = wave.open(filename, 'rb')
     bytes_per_sample = wf.getsampwidth()
     bits_per_sample  = bytes_per_sample * 8
     dtype = 'int{0}'.format(bits_per_sample)
     channels = wf.getnchannels()
     n_bytes_per_sample=bytes_per_sample
     n_channels=channels
     sampling = fs
     duration=60
     CHUNK = 1024
     audio = np.frombuffer(wf.readframes(int(duration*fs*bytes_per_sample/channels)), dtype=dtype)
     
     
     Q = multiprocessing.Queue()
     
     p1 = multiprocessing.Process(target=run_display)
     p1.start()     
     p2 = multiprocessing.Process(target=audiostream, args=(Q,filename))
     p2.start()
     p1.join()
     p2.join()
```
























